{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iy7MiVWZzUCo"
      },
      "source": [
        "##Installs, setup, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MR1M1N6ry6VI"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7jCgzZGMzCTK"
      },
      "outputs": [],
      "source": [
        "#assumes we already have tensorflow installed (e.g. on colab)\n",
        "%%capture\n",
        "!sudo apt install -y fluidsynth\n",
        "!pip install --upgrade pyfluidsynth\n",
        "!pip install muspy #important to have this last, \n",
        "                   #otherwise it interferes with fluidsynth version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VUu2tVnvzGQK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import glob\n",
        "import numpy as np\n",
        "import torchtext\n",
        "import muspy\n",
        "import fluidsynth\n",
        "import os\n",
        "import music21\n",
        "import pandas as pd\n",
        "import random\n",
        "import keras.utils\n",
        "import time\n",
        "import csv\n",
        "import shutil\n",
        "from os import path\n",
        "from IPython import display\n",
        "from more_itertools import sliced\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from matplotlib import pyplot as plt\n",
        "from cgi import test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-t7ZopYhzHTG"
      },
      "outputs": [],
      "source": [
        "muspy.download_musescore_soundfont()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ug175COj-pHa"
      },
      "source": [
        "## constants/hyperparamters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "99Mshb5XzI5X"
      },
      "outputs": [],
      "source": [
        "#options\n",
        "dataset_choice = 'MAESTRO' #JSB or MAESTRO\n",
        "\n",
        "#constants\n",
        "NO_FILES = 7\n",
        "SAMPLING_RATE = 16000\n",
        "VOCAB_SIZE = 355  #356 for event no velocity, 388 for event w/ velocity, \n",
        "\n",
        "#hyperparameters \n",
        "nn_size_options = ['small', 'medium', 'large']\n",
        "nn_size_default = nn_size_options[1]\n",
        "NN_SIZE = nn_size_default\n",
        "\n",
        "lr_options = [0.01, 0.001, 0.0001]\n",
        "lr_default = lr_options[1]\n",
        "LEARNING_RATE = lr_default\n",
        "\n",
        "dropout_options = [0.0, 0.3, 0.4 , 0.5]\n",
        "dropout_default = dropout_options[0]\n",
        "DROPOUT = dropout_options[2]\n",
        "\n",
        "batch_options = [32, 64, 128]\n",
        "batch_default = batch_options[1]\n",
        "BATCH_SIZE = batch_options[2]\n",
        "\n",
        "seq_len_options = [25, 50, 100]\n",
        "seq_len_default = seq_len_options[1]\n",
        "SEQ_LENGTH = seq_len_default\n",
        "\n",
        "recurrent_dropout_options = [0.0, 0.3, 0.4, 0.5] #where 0.0 means disabled\n",
        "recurrent_dropout_default = recurrent_dropout_options[0]\n",
        "RECURRENT_DROPOUT = recurrent_dropout_default\n",
        "\n",
        "using_batch_norm = [False, True]\n",
        "batch_norm_default = using_batch_norm[0]\n",
        "BATCH_NORM = using_batch_norm[1]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djdly3s_-lii"
      },
      "source": [
        "##get datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "A7Zt0-gtkMhd"
      },
      "outputs": [],
      "source": [
        "if dataset_choice == 'JSB':\n",
        "  #download dataset (JSB)\n",
        "  files = []\n",
        "\n",
        "  if not (path.exists('/content/JSB%20Chorales.zip')):\n",
        "    url = 'http://www-ens.iro.umontreal.ca/~boulanni/JSB%20Chorales.zip'\n",
        "    from_path = './JSB%20Chorales.zip'\n",
        "    to_path = './'\n",
        "\n",
        "    torchtext.utils.download_from_url(url, from_path)\n",
        "    torchtext.utils.extract_archive(from_path, to_path)\n",
        "  else: print('Already downloaded the JSB Chorales dataset.')\n",
        "\n",
        "  train_files = glob.glob('JSB Chorales/train/*.mid*') #create list of all .midi files\n",
        "  valid_files = glob.glob('JSB Chorales/valid/*.mid*') #create list of all .midi files\n",
        "  test_files = glob.glob('JSB Chorales/test/*.mid*') #create list of all .midi files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pj3-s5xohGwy"
      },
      "outputs": [],
      "source": [
        "if dataset_choice == 'MAESTRO':\n",
        "\n",
        "  #download dataset (MAESTRO)\n",
        "  files = []\n",
        "\n",
        "  if not (path.exists('/content/maestro-v3.0.0')):\n",
        "    url = 'https://storage.googleapis.com/magentadata/datasets/maestro/v3.0.0/maestro-v3.0.0-midi.zip'\n",
        "    from_path = './maestro-v3.0.0-midi.zip'\n",
        "    to_path = './'\n",
        "\n",
        "    torchtext.utils.download_from_url(url, from_path)\n",
        "    torchtext.utils.extract_archive(from_path, to_path)\n",
        "  else: print('Already downloaded the MAESTRO V3 dataset.')\n",
        "\n",
        "  csv = '/content/maestro-v3.0.0/maestro-v3.0.0.csv'\n",
        "  col_list = [\"split\", \"midi_filename\"]\n",
        "  df = pd.read_csv(csv, usecols=col_list)\n",
        "\n",
        "  num_files = len(df.index)\n",
        "\n",
        "  test_files = []\n",
        "  valid_files = []\n",
        "  train_files = []\n",
        "\n",
        "  for i in range(num_files):\n",
        "\n",
        "    if df['split'][i] == 'test':    \n",
        "      filename = df['midi_filename'][i]\n",
        "      #sliced_filename = filename[5:]\n",
        "      test_files.append('/content/maestro-v3.0.0/' + filename)\n",
        "\n",
        "    if df['split'][i] == 'validation':    \n",
        "      filename = df['midi_filename'][i]\n",
        "      #sliced_filename = filename[5:]\n",
        "      valid_files.append('/content/maestro-v3.0.0/' + filename)\n",
        "\n",
        "    if df['split'][i] == 'train':    \n",
        "      filename = df['midi_filename'][i]\n",
        "      #sliced_filename = filename[5:]\n",
        "      train_files.append('/content/maestro-v3.0.0/' + filename)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27Cjdg-Cxzx4"
      },
      "source": [
        "##MIDI processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "WBdd3BayySnJ"
      },
      "outputs": [],
      "source": [
        "midi_file = train_files[0]\n",
        "music = muspy.read_midi(midi_file)\n",
        "RESOLUTION = music.resolution #get resolution for MIDI creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9amtgopKx2oy"
      },
      "outputs": [],
      "source": [
        "def tensor_to_muspy(music_tensor) -> muspy.Music:\n",
        "\n",
        "  music_array = denormalise(music_tensor)\n",
        "  music_array = np.around(music_array)\n",
        "  music_array = music_array.astype(int)\n",
        "\n",
        "  music_array = append_note_off(music_array)\n",
        "  music = muspy.from_event_representation(music_array, resolution=RESOLUTION)\n",
        "  return music"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-wAFpr1Bx3HR"
      },
      "outputs": [],
      "source": [
        "def append_note_off(event_array):\n",
        "  #convert from [1, 2, 3] to [[1], [2], [3]] for muspy compatability\n",
        "  event_array = [[i] for i in event_array]\n",
        "  note_offs = np.arange(128, 256)\n",
        "  note_offs = [[i] for i in note_offs]\n",
        "  eos_array = np.concatenate((event_array, note_offs))\n",
        "  return eos_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bjQqKgA7y145"
      },
      "outputs": [],
      "source": [
        "def muspy_to_audio(music: muspy.Music):\n",
        "  raw_audio = muspy.synthesize(music, rate=SAMPLING_RATE)\n",
        "  time = 30 #max length of excerpt\n",
        "  excerpt = raw_audio[:time*SAMPLING_RATE]\n",
        "  return display.Audio(excerpt.T, rate=SAMPLING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "CQ5HflguWDdf"
      },
      "outputs": [],
      "source": [
        "def normalise(music: np.ndarray) -> np.ndarray:\n",
        "    return music/VOCAB_SIZE\n",
        "    \n",
        "def denormalise(music: np.ndarray)-> np.ndarray:\n",
        "    return music*VOCAB_SIZE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muNoku_YzykK"
      },
      "source": [
        "##Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnBgdKrUfbWe"
      },
      "source": [
        " creating the actual dataset of arrays, from midi files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "A2KItjs7z2Av"
      },
      "outputs": [],
      "source": [
        "train_dataset = []\n",
        "validate_dataset = []\n",
        "test_dataset = []\n",
        "\n",
        "metrics_set = [] #used to get average metrics for comparison later\n",
        "\n",
        "total_notes = 0\n",
        "\n",
        "random.shuffle(train_files)\n",
        "random.shuffle(valid_files)\n",
        "random.shuffle(test_files)\n",
        "\n",
        "splits = [0.8, 0.1, 0.1] #values here should add to 1\n",
        "\n",
        "\n",
        "if dataset_choice == 'MAESTRO':\n",
        "  train_files = train_files[:round(NO_FILES*splits[0])]\n",
        "  valid_files = valid_files[:round(NO_FILES*splits[1])]\n",
        "  test_files = test_files[:round(NO_FILES*splits[2])]\n",
        "\n",
        "for file in train_files:\n",
        "  midi_file = muspy.read_midi(file)\n",
        "  metrics_set.append(midi_file)\n",
        "  train_dataset.append(muspy.to_event_representation(midi_file, use_single_note_off_event=False))\n",
        "  total_notes += muspy.to_event_representation(midi_file, use_single_note_off_event=False).size\n",
        "  \n",
        "for file in valid_files: \n",
        "  midi_file = muspy.read_midi(file)\n",
        "  metrics_set.append(midi_file)\n",
        "  validate_dataset.append(muspy.to_event_representation(midi_file, use_single_note_off_event=False))\n",
        "  total_notes += muspy.to_event_representation(midi_file, use_single_note_off_event=False).size\n",
        "\n",
        "for file in test_files:\n",
        "  midi_file = muspy.read_midi(file)\n",
        "  metrics_set.append(midi_file)\n",
        "  test_dataset.append(muspy.to_event_representation(midi_file, use_single_note_off_event=False))\n",
        "  total_notes += muspy.to_event_representation(midi_file, use_single_note_off_event=False).size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "9vtzB7kKV732"
      },
      "outputs": [],
      "source": [
        "def convert_array(array_ds):\n",
        "  array_ds = np.concatenate(array_ds).ravel() #turns tuple of numpy arrays into a flat 1d numpy array   \n",
        "  return array_ds\n",
        "\n",
        "def create_features(array_ds):\n",
        "  array_ds = tf.convert_to_tensor(array_ds, dtype=tf.float32)\n",
        "  array_ds = tf.data.Dataset.from_tensor_slices(array_ds)\n",
        "  array_ds = array_ds.batch(1)\n",
        "\n",
        "  array_ds = array_ds.window(SEQ_LENGTH+1, shift=1, stride=1, drop_remainder=True)\n",
        "  array_ds = array_ds.flat_map(lambda x: x.batch(SEQ_LENGTH+1, drop_remainder=True))\n",
        "\n",
        "  return array_ds\n",
        "\n",
        "def create_target(array_ds):\n",
        "  test_ds = array_ds[:-1]\n",
        "  test_ds = normalise(test_ds)\n",
        "\n",
        "  target = array_ds[-1]\n",
        "  target = tf.cast(target, tf.int32)\n",
        "  target = tf.one_hot(target, VOCAB_SIZE+1)\n",
        "  target = tf.squeeze(target)\n",
        "\n",
        "  return test_ds, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "0QrnJc-nYfh0"
      },
      "outputs": [],
      "source": [
        "train_dataset = convert_array(train_dataset) #flat array\n",
        "validate_dataset = convert_array(validate_dataset)\n",
        "test_dataset = convert_array(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "COGcE3qebINQ"
      },
      "outputs": [],
      "source": [
        "train_dataset = create_features(train_dataset)   #groups of seq length tensors\n",
        "train_dataset = train_dataset.map(create_target) #groups of seq length tensors, \n",
        "                                                 #with 1 target note (in one-hot format)\n",
        "train_dataset = (train_dataset.shuffle(total_notes+1).batch(BATCH_SIZE, drop_remainder=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "ORUZpEqYYT4R"
      },
      "outputs": [],
      "source": [
        "validate_dataset = create_features(validate_dataset)\n",
        "validate_dataset = validate_dataset.map(create_target)\n",
        "validate_dataset = (validate_dataset.shuffle(total_notes+1).batch(BATCH_SIZE, drop_remainder=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "tFXnUqCy3awM"
      },
      "outputs": [],
      "source": [
        "test_dataset = create_features(test_dataset)\n",
        "test_dataset = test_dataset.map(create_target)\n",
        "test_dataset = (test_dataset.shuffle(total_notes+1).batch(BATCH_SIZE, drop_remainder=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHvk77Uvf6p_"
      },
      "source": [
        "##Create lstm\n",
        "This section defines a Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "HOMAET5pf9p0"
      },
      "outputs": [],
      "source": [
        "def build_model():\n",
        "  if NN_SIZE == 'small':\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.LSTM(\n",
        "        128,\n",
        "        input_shape=(SEQ_LENGTH, 1),\n",
        "        return_sequences=False\n",
        "    ))\n",
        "    if BATCH_NORM == True:\n",
        "      model.add(tf.keras.layers.BatchNormalization(momentum=0.9))\n",
        "    \n",
        "    model.add(tf.keras.layers.Dropout(DROPOUT))\n",
        "    model.add(tf.keras.layers.Dense(128))\n",
        "    model.add(tf.keras.layers.Activation('relu'))\n",
        "    if BATCH_NORM == True:\n",
        "      model.add(tf.keras.layers.BatchNormalization(momentum=0.9))\n",
        "    \n",
        "    model.add(tf.keras.layers.Dropout(DROPOUT))\n",
        "    model.add(tf.keras.layers.Dense(VOCAB_SIZE+1))\n",
        "    model.add(tf.keras.layers.Softmax())\n",
        "\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "    model.compile(loss=loss, optimizer=optimizer) \n",
        "\n",
        "  elif NN_SIZE == 'medium':\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.LSTM(\n",
        "        256,\n",
        "        input_shape=(SEQ_LENGTH, 1),\n",
        "        recurrent_dropout=RECURRENT_DROPOUT,\n",
        "        return_sequences=True\n",
        "    ))\n",
        "    model.add(tf.keras.layers.LSTM(\n",
        "        256, \n",
        "        return_sequences=False,\n",
        "    ))\n",
        "    if BATCH_NORM == True:\n",
        "      model.add(tf.keras.layers.BatchNormalization(momentum=0.9))\n",
        "    \n",
        "    model.add(tf.keras.layers.Dropout(DROPOUT))\n",
        "    model.add(tf.keras.layers.Dense(128))\n",
        "    model.add(tf.keras.layers.Activation('relu'))\n",
        "    if BATCH_NORM == True:\n",
        "      model.add(tf.keras.layers.BatchNormalization(momentum=0.9))\n",
        "    \n",
        "    model.add(tf.keras.layers.Dropout(DROPOUT))\n",
        "    model.add(tf.keras.layers.Dense(VOCAB_SIZE+1))\n",
        "    model.add(tf.keras.layers.Softmax())\n",
        "\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "    model.compile(loss=loss, optimizer=optimizer) \n",
        "    \n",
        "  elif NN_SIZE == 'large':\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.LSTM(\n",
        "        512,\n",
        "        input_shape=(SEQ_LENGTH, 1),\n",
        "        recurrent_dropout=RECURRENT_DROPOUT,\n",
        "        return_sequences=True\n",
        "    ))\n",
        "    model.add(tf.keras.layers.LSTM(\n",
        "        512, \n",
        "        return_sequences=True,\n",
        "    ))\n",
        "    model.add(tf.keras.layers.LSTM(\n",
        "        512, \n",
        "        return_sequences=False,\n",
        "    ))\n",
        "    if BATCH_NORM == True:\n",
        "      model.add(tf.keras.layers.BatchNormalization(momentum=0.9))\n",
        "    \n",
        "    model.add(tf.keras.layers.Dropout(DROPOUT))\n",
        "    model.add(tf.keras.layers.Dense(256))\n",
        "    model.add(tf.keras.layers.Activation('relu'))\n",
        "    if BATCH_NORM == True:\n",
        "      model.add(tf.keras.layers.BatchNormalization(momentum=0.9))\n",
        "    \n",
        "    model.add(tf.keras.layers.Dropout(DROPOUT))\n",
        "    model.add(tf.keras.layers.Dense(256))\n",
        "    model.add(tf.keras.layers.Activation('relu'))\n",
        "    if BATCH_NORM == True:\n",
        "      model.add(tf.keras.layers.BatchNormalization(momentum=0.9))\n",
        "    \n",
        "    model.add(tf.keras.layers.Dropout(DROPOUT))\n",
        "    model.add(tf.keras.layers.Dense(VOCAB_SIZE+1))\n",
        "    model.add(tf.keras.layers.Softmax())\n",
        "\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "    model.compile(loss=loss, optimizer=optimizer)\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTAedLYMkoYu"
      },
      "source": [
        "##print"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skxRX7QuMOU0"
      },
      "outputs": [],
      "source": [
        "print('model size: ', NN_SIZE, ' dropout: ', DROPOUT, ' learning rate: ', LEARNING_RATE, ' sequence length: ', SEQ_LENGTH, ' batch size: ', BATCH_SIZE, ' recurrent dropout: ', RECURRENT_DROPOUT, ' batch norm: ', BATCH_NORM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1G1v1IsJiFV"
      },
      "source": [
        "##training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "xdjFcbH5kI1A"
      },
      "outputs": [],
      "source": [
        "class TimeHistory(keras.callbacks.Callback): \n",
        "#from https://stackoverflow.com/questions/43178668/record-the-computation-time-for-each-epoch-in-keras-during-model-fit\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.times = []\n",
        "\n",
        "    def on_epoch_begin(self, batch, logs={}):\n",
        "        self.epoch_time_start = time.time()\n",
        "\n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "        self.times.append(time.time() - self.epoch_time_start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "XVrH0xxEkSXq"
      },
      "outputs": [],
      "source": [
        "time_callback = TimeHistory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfUfX5DCipyO"
      },
      "outputs": [],
      "source": [
        "filepath = '/content/drive/MyDrive/Checkpoints/ckpt{epoch:02d}.hdf5'\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=filepath,\n",
        "        #save_best_only=True,\n",
        "        save_freq='epoch',\n",
        "        save_weights_only=True,\n",
        "        period=50),\n",
        "        \n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='loss',\n",
        "        patience=5,\n",
        "        restore_best_weights=True),\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=8,\n",
        "        restore_best_weights=False),\n",
        "    time_callback,\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58kN9MXjiuUs"
      },
      "outputs": [],
      "source": [
        "val_losses = []\n",
        "epoch_recorded = []\n",
        "\n",
        "num_runs = 1\n",
        "\n",
        "for i in range(num_runs):\n",
        "  model = build_model()\n",
        "  history = model.fit(\n",
        "      train_dataset,\n",
        "      epochs=100,\n",
        "      callbacks=callbacks,\n",
        "      validation_data=validate_dataset\n",
        "  )\n",
        "  lowest = min(history.history['val_loss'])\n",
        "  val_losses.append(lowest)\n",
        "\n",
        "  epoch_idx = history.history['val_loss'].index(lowest) + 1\n",
        "  epoch_recorded.append(epoch_idx)\n",
        "\n",
        "avg_val_loss = round(sum(val_losses)/num_runs, 4) \n",
        "times = time_callback.times\n",
        "avg_times = round(sum(times)/len(times))\n",
        "avg_epoch_recorded = round(sum(epoch_recorded)/len(epoch_recorded))\n",
        "\n",
        "print('average val_loss: ', avg_val_loss)\n",
        "print('average time per epoch: ', avg_times)\n",
        "print('average best epoch_recorded: ', avg_epoch_recorded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGoCGpg7oxPs"
      },
      "outputs": [],
      "source": [
        "dic1 = {'average val_loss: ': [avg_val_loss], 'average time per epoch: ': [avg_times], 'average best epoch_recorded: ': [avg_epoch_recorded]}\n",
        "df = pd.DataFrame(dic1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sxod2SogFVQG"
      },
      "outputs": [],
      "source": [
        "#model.summary()\n",
        "#plot_model(model, to_file='model.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfhnQySP8gZw"
      },
      "outputs": [],
      "source": [
        "#model.load_weights('/content/drive/MyDrive/Checkpoints/jsb300/ckpt300.hdf5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4VOfx07l-ZZ"
      },
      "outputs": [],
      "source": [
        "#model.save(filepath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dO9uHYirZwtr"
      },
      "source": [
        "##Generate music"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "w3bbpxJSzvDK"
      },
      "outputs": [],
      "source": [
        "def get_random_sequence():\n",
        "  rand = random.randrange(len(test_files))\n",
        "  music = muspy.read_midi(test_files[rand])\n",
        "  music = muspy.to_event_representation(music)\n",
        "  rand = random.randrange((len(music) - SEQ_LENGTH) - 1)\n",
        "  music = music[rand:SEQ_LENGTH+rand]\n",
        "  #music = music[0:SEQ_LENGTH] #enable to test from beginning of piece \n",
        "  music = normalise(music)\n",
        "\n",
        "  return music"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "lStrYrgDZuHy"
      },
      "outputs": [],
      "source": [
        "def predict(music, model):\n",
        "    input_seq = tf.expand_dims(music, 0)\n",
        "    softmax_output = model.predict(input_seq)\n",
        "    events = np.squeeze(softmax_output)\n",
        "    event = np.argmax(events)\n",
        "    return event"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kz79hSEDz2g_"
      },
      "outputs": [],
      "source": [
        "songs = 10 #how many pieces we want to generate\n",
        "muspy_songs = []\n",
        "\n",
        "for i in range(songs):\n",
        "\n",
        "  music = get_random_sequence()\n",
        "\n",
        "  no_preds = 400 #how many generated notes we want (400 is about 25 seconds on JSB chorales)\n",
        "  generated = []\n",
        "\n",
        "  for i in range (no_preds):                       \n",
        "    note = predict(music, model)\n",
        "    generated.append(normalise(note))\n",
        "    music = np.append(music, normalise(note))\n",
        "    music = music[1:]\n",
        "\n",
        "  #print(generated)\n",
        "  generated = np.asarray(generated)\n",
        "  music = tensor_to_muspy(generated)\n",
        "  muspy_songs.append(music)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXNz1zPJxlHB"
      },
      "outputs": [],
      "source": [
        "#muspy_to_audio(muspy_songs[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjjWXBW1fRT9"
      },
      "outputs": [],
      "source": [
        "#muspy.write_audio('/content/drive/MyDrive/Generated/300epochs.wav', muspy_songs[0], audio_format='wav', rate=SAMPLING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGUZo3ipbutQ"
      },
      "outputs": [],
      "source": [
        "muspy.show_pianoroll(muspy_songs[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6P39n_FRiSS"
      },
      "source": [
        "##Metrics\n",
        "This section defines metrics which can be used in order to evaluate the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1GUcA9_hJLB"
      },
      "outputs": [],
      "source": [
        "def get_pitch_metrics(muspy_songs): \n",
        "  #returns a tuple of number of different pitch values per generated song, \n",
        "  #with last element the mean of the whole set\n",
        "\n",
        "  songs = []\n",
        "  total_pitches_used = 0\n",
        "\n",
        "  for song in muspy_songs:\n",
        "    song_pitches = muspy.n_pitches_used(song)\n",
        "    songs.append(song_pitches)\n",
        "    total_pitches_used += muspy.n_pitches_used(song)\n",
        "  \n",
        "  mean = total_pitches_used/len(songs)\n",
        "  songs.append(mean)\n",
        "\n",
        "  return songs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fq2Qv-g1nubL"
      },
      "outputs": [],
      "source": [
        "def get_polyphony_rates(muspy_songs): \n",
        "  #returns a tuple of polyphony values (how many notes played at once) per generated song, \n",
        "  #with last element the mean of the whole set\n",
        "  songs = []\n",
        "  total_polyphony = 0\n",
        "\n",
        "  for song in muspy_songs:\n",
        "    song_polyphony = muspy.polyphony(song)\n",
        "    songs.append(song_polyphony)\n",
        "    total_polyphony += muspy.polyphony(song)\n",
        "  \n",
        "  mean = total_polyphony/len(songs)\n",
        "  songs.append(mean)\n",
        "\n",
        "  return songs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvYeBlPpjuwT"
      },
      "outputs": [],
      "source": [
        "dataset_generated_song_pitches = get_pitch_metrics(metrics_set)\n",
        "dataset_generated_mean_song_pitches = dataset_generated_song_pitches[-1]\n",
        "dataset_generated_song_pitches = dataset_generated_song_pitches[:-1]\n",
        "\n",
        "dataset_generated_polyphony_rates = get_polyphony_rates(metrics_set)\n",
        "dataset_generated_mean_polyphony_rates = dataset_generated_polyphony_rates[-1]\n",
        "dataset_generated_polyphony_rates = dataset_generated_polyphony_rates[:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hk07_hLmSqfT"
      },
      "outputs": [],
      "source": [
        "generated_song_pitches = get_pitch_metrics(muspy_songs)\n",
        "generated_mean_song_pitches = generated_song_pitches[-1]\n",
        "generated_song_pitches = generated_song_pitches[:-1]\n",
        "\n",
        "generated_polyphony_rates = get_polyphony_rates(muspy_songs)\n",
        "generated_mean_polyphony_rates = generated_polyphony_rates[-1]\n",
        "generated_polyphony_rates = generated_polyphony_rates[:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYb6_pvGPIaP"
      },
      "outputs": [],
      "source": [
        "dic2 = {'average pitches': [generated_mean_song_pitches], 'average polyphony': [generated_mean_polyphony_rates]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPMPYRUwrcdI"
      },
      "outputs": [],
      "source": [
        "dicall = {}\n",
        "dicall.update(dic1)\n",
        "dicall.update(dic2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxl4y8bcrtcn"
      },
      "source": [
        "##final results\n",
        "\n",
        "the final results of an experiment are saved to a folder, as well as a loss graph from one of the models as a sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LQZ2G0S4yx3"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(dicall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKU2Vdzz8d6r"
      },
      "outputs": [],
      "source": [
        "filename = NN_SIZE + '_d' + str(DROPOUT) + '_lr'  + str(LEARNING_RATE) + '_sl'  + str(SEQ_LENGTH) + '_bs'  + str(BATCH_SIZE) + '_rd'  + str(RECURRENT_DROPOUT) + '_bn'  + str(BATCH_NORM)\n",
        "\n",
        "if filename == 'medium_d0.0_lr0.001_sl50_bs64_rd0.0_bnFalse':\n",
        "  filename = 'defaults'\n",
        "folder = '/content/drive/MyDrive/Experiments/' + filename\n",
        "if not (path.exists(folder)):\n",
        "  os.mkdir(folder)\n",
        "dffile = folder + '/' + 'statistics.csv'\n",
        "df.to_csv(dffile) \n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper right')\n",
        "plt.draw()\n",
        "\n",
        "imagefile = folder + '/' + 'graph.png'\n",
        "plt.savefig(imagefile)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "djdly3s_-lii",
        "UHvk77Uvf6p_"
      ],
      "machine_shape": "hm",
      "name": "hons_lstm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
